{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 43,\n",
       " 10,\n",
       " 447,\n",
       " 5,\n",
       " 25,\n",
       " 207,\n",
       " 270,\n",
       " 5,\n",
       " 3095,\n",
       " 111,\n",
       " 16,\n",
       " 369,\n",
       " 186,\n",
       " 90,\n",
       " 67,\n",
       " 7,\n",
       " 89,\n",
       " 5,\n",
       " 19,\n",
       " 102,\n",
       " 6,\n",
       " 19,\n",
       " 124,\n",
       " 15,\n",
       " 90,\n",
       " 67,\n",
       " 84,\n",
       " 22,\n",
       " 482,\n",
       " 26,\n",
       " 7,\n",
       " 48,\n",
       " 4,\n",
       " 49,\n",
       " 8,\n",
       " 864,\n",
       " 39,\n",
       " 209,\n",
       " 154,\n",
       " 6,\n",
       " 151,\n",
       " 6,\n",
       " 83,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 155,\n",
       " 11,\n",
       " 15,\n",
       " 7,\n",
       " 48,\n",
       " 9,\n",
       " 4579,\n",
       " 1005,\n",
       " 504,\n",
       " 6,\n",
       " 258,\n",
       " 6,\n",
       " 272,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 134,\n",
       " 44,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 197,\n",
       " 1245,\n",
       " 90,\n",
       " 67,\n",
       " 52,\n",
       " 29,\n",
       " 209,\n",
       " 30,\n",
       " 32,\n",
       " 132,\n",
       " 6,\n",
       " 109,\n",
       " 15,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "decoded_newswire = ''.join([reverse_word_index.get(i-3,'?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???saidasaresultofitsdecemberacquisitionofspacecoitexpectsearningspersharein1987of115to130dlrspershareupfrom70ctsin1986thecompanysaidpretaxnetshouldrisetonineto10mlndlrsfromsixmlndlrsin1986andrentaloperationrevenuesto19to22mlndlrsfrom125mlndlrsitsaidcashflowpersharethisyearshouldbe250tothreedlrsreuter3\n"
     ]
    }
   ],
   "source": [
    "print(decoded_newswire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences,dimension=10000):\n",
    "    results = np.zeros((len(sequences),dimension))\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels,dimension=46):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 3s 370us/step - loss: 2.5319 - acc: 0.4956 - val_loss: 1.7200 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 1.4448 - acc: 0.6883 - val_loss: 1.3453 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 1.0948 - acc: 0.7656 - val_loss: 1.1714 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.8695 - acc: 0.8161 - val_loss: 1.0780 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.7034 - acc: 0.8477 - val_loss: 0.9859 - val_acc: 0.7820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.5669 - acc: 0.8797 - val_loss: 0.9423 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.4583 - acc: 0.9050 - val_loss: 0.9092 - val_acc: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.3697 - acc: 0.9226 - val_loss: 0.9364 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.3036 - acc: 0.9310 - val_loss: 0.8912 - val_acc: 0.8080\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.2541 - acc: 0.9414 - val_loss: 0.9056 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.2187 - acc: 0.9469 - val_loss: 0.9171 - val_acc: 0.8120\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.1872 - acc: 0.9509 - val_loss: 0.9055 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.1703 - acc: 0.9525 - val_loss: 0.9351 - val_acc: 0.8100\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1536 - acc: 0.9555 - val_loss: 0.9701 - val_acc: 0.8070\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1390 - acc: 0.9555 - val_loss: 0.9700 - val_acc: 0.8140\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1315 - acc: 0.9563 - val_loss: 1.0255 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1218 - acc: 0.9578 - val_loss: 1.0245 - val_acc: 0.7980\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.1197 - acc: 0.9577 - val_loss: 1.0440 - val_acc: 0.8070\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1136 - acc: 0.9597 - val_loss: 1.1002 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1112 - acc: 0.9590 - val_loss: 1.0711 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "7982/7982 [==============================] - 1s 187us/step - loss: 2.5358 - acc: 0.5228 - val_loss: 1.6794 - val_acc: 0.6530\n",
      "Epoch 2/8\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 1.3746 - acc: 0.7122 - val_loss: 1.2799 - val_acc: 0.7230\n",
      "Epoch 3/8\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 1.0187 - acc: 0.7788 - val_loss: 1.1342 - val_acc: 0.7510\n",
      "Epoch 4/8\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.8030 - acc: 0.8240 - val_loss: 1.0556 - val_acc: 0.7580\n",
      "Epoch 5/8\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.6435 - acc: 0.8611 - val_loss: 0.9773 - val_acc: 0.7950\n",
      "Epoch 6/8\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.5144 - acc: 0.8918 - val_loss: 0.9105 - val_acc: 0.8110\n",
      "Epoch 7/8\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.4134 - acc: 0.9143 - val_loss: 0.8944 - val_acc: 0.8220\n",
      "Epoch 8/8\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.3368 - acc: 0.9283 - val_loss: 0.8720 - val_acc: 0.8270\n",
      "2246/2246 [==============================] - 0s 173us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=8,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9821485175899597, 0.7871772039180766]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
